{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:76: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:77: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:79: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:80: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:81: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:82: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:83: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:84: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:85: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:86: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:87: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:88: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:89: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:90: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:91: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:92: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:107: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clear_over\n",
      "test feat over\n",
      "train feat over\n",
      "开始训练......\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:233: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:234: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:235: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "D:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:237: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=True'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass sort=False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Aug 22 17:12:53 2018\n",
    "\n",
    "@author: Medcare,Wan\n",
    "\"\"\"\n",
    "# score 58.80403\n",
    "# rank 19+\n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler,MinMaxScaler\n",
    "path='C:/Users/wwwkd/Desktop/competition/data'\n",
    "pre_data=pd.read_csv(path+'/data_pre.csv')\n",
    "test_data=pd.read_csv(path+'/tap_fun_test.csv')\n",
    "train_data=pd.read_csv(path+'/tap_fun_train.csv')\n",
    "\n",
    "#------------------------------------------------\n",
    "import datetime\n",
    "import numpy\n",
    "# 国内公测时间 2017年8月13日\n",
    "# 增加 test_data 的 注册日期距离公测时间的天数\n",
    "def add_time_dif(array):\n",
    "    new_array = numpy.zeros(shape=(array.shape[0],1))\n",
    "\n",
    "    for i in np.arange(array['register_time'].shape[0]):\n",
    "        the_array = array['register_time']\n",
    "        sd = datetime.datetime.strptime('2017-08-13 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "        d = datetime.datetime.strptime(the_array[i], '%Y-%m-%d %H:%M:%S')\n",
    "        time = (d - sd).days + 1\n",
    "        new_array[i] = int(time)    \n",
    "    array['time_dif'] = new_array\n",
    "    #修改为int16 减少计算量\n",
    "    array['time_dif'] = numpy.int16(array['time_dif'])\n",
    "    return array\n",
    "    # print (test_data['time_dif'])\n",
    "test_data = add_time_dif(test_data)\n",
    "\n",
    "# 增加 train_data 的 注册日期距离公测时间的天数\n",
    "def my_none():\n",
    "    new_array = numpy.zeros(shape=(train_data.shape[0],1))\n",
    "    array = np.array(train_data['register_time']).reshape(len(train_data['register_time']),1)\n",
    "    for i in np.arange(train_data['register_time'].shape[0]):\n",
    "\n",
    "        sd = datetime.datetime.strptime('2017-08-13 00:00:00', '%Y-%m-%d %H:%M:%S')\n",
    "        d = datetime.datetime.strptime(array[i,0], '%Y-%m-%d %H:%M:%S')\n",
    "        time = (d - sd).days + 1\n",
    "        new_array[i] = int(time)    \n",
    "    train_data['time_dif'] = new_array\n",
    "    # #修改为int16 减少计算量\n",
    "    train_data['time_dif'] = numpy.int16(train_data['time_dif'])\n",
    "my_none()\n",
    "\n",
    "#-----------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "train_data.drop_duplicates( keep='first', inplace=True)\n",
    "del train_data['register_time'],test_data['register_time']\n",
    "pre_data.drop_duplicates( keep='first', inplace=True)\n",
    "train_data=train_data[train_data['pay_price']>0]\n",
    "test_data_prect=test_data[test_data['pay_price']>0]\n",
    "test_data_rule=test_data[test_data['pay_price']==0]\n",
    "'''\n",
    "def data_clear(df):\n",
    "    temp=pd.DataFrame(index=range(1))\n",
    "    temp['user_id']=df['user_id'].unique()[0]\n",
    "    clear_sum=0\n",
    "    for i in pre_data['wood']:\n",
    "        clear_sum=df[str(i)+'_reduce_value'].max()+clear_sum\n",
    "    if clear_sum==0:\n",
    "        temp['is_clear']=1\n",
    "    else:\n",
    "        temp['is_clear']=0\n",
    "    return temp    \n",
    "'''\n",
    "def rate_feat(df):\n",
    "    for i in pre_data['wood']:\n",
    "        df[str(i)+'rate']=df[str(i)+'_reduce_value']/df[str(i)+'_add_value']        \n",
    "    df['pvp_rate']=df['pvp_lanch_count']/df['pvp_battle_count']\n",
    "    df['pvp_win_rate']=df['pvp_win_count']/df['pvp_battle_count']\n",
    "    df['pay_count_rate']=df['pay_count']/df['avg_online_minutes']\n",
    "    df['pay_mean']=df['pay_price']/df['pay_count']\n",
    "    df['pve_win_rate']=df['pve_win_count']/df['pve_battle_count']\n",
    "    df['battle_count']=df['pve_battle_count']+df['pvp_battle_count']\n",
    "    df['pvp_battle_rate']=df['pve_battle_count']/df['battle_count']\n",
    "    df['win_rate']=(df['pve_win_count']+df['pvp_win_count'])/df['pvp_battle_rate']\n",
    "    df['pve_rate']=df['pve_lanch_count']/df['pve_battle_count']\n",
    "    df['lanch_count']=df['pvp_lanch_count']+df['pve_lanch_count']\n",
    "    df['lanch_rate']=df['pvp_lanch_count']/df['lanch_count']\n",
    "    df['battle_rate']=df['pvp_battle_count']/df['pve_battle_count']\n",
    "    df['lauch_battle_rate']=df['pvp_lanch_count']/df['pve_lanch_count']\n",
    "    df['treat_rate']=df['treatment_acceleration_reduce_value']/df['treatment_acceleraion_add_value']\n",
    "    df['shaman_battle_rate']=df['shaman_reduce_value']/df['battle_count']    \n",
    "    df['cavalry_battle_rate']=df['cavalry_reduce_value']/df['battle_count']\n",
    "    df['infantry_battle_rate']=df['infantry_reduce_value']/df['battle_count']\n",
    "    #df['infantry_loss_battle_rates']=(df['infantry_reduce_value']+df['wound_infantry_add_value'])/df['battle_count']\n",
    "    #df['cavalry_loss_battle_rates']=(df['cavalry_reduce_value']+df['wound_cavalry_add_value'])/df['battle_count']\n",
    "    #df['shaman_loss_battle_rates']=(df['shaman_reduce_value']+df['wound_shaman_add_value'])/df['battle_count']\n",
    "    \n",
    "    \n",
    "    df['pvp_passive_rate']=(df['pvp_battle_count']-df['pve_lanch_count'])/df['time_dif']\n",
    "\n",
    "    \n",
    "    #df['all_reduce_count']=df['infantry_reduce_value']+df['cavalry_reduce_value']+df['shaman_reduce_value']\n",
    "    #df['sodier_count']=df['infantry_add_value']+df['cavalry_add_value']+df['shaman_add_value']\n",
    "    #df['infantry_add_rate']=df['infantry_add_value']/df['sodier_count']\n",
    "    #df['cavalry_add_rate']=df['cavalry_add_value']/df['sodier_count']\n",
    "    #df['shaman_add_rate']=df['shaman_add_value']/df['sodier_count']\n",
    "    #df['wound_left_count']=df['wound_cavalry_reduce_value']+df['wound_infantry_reduce_value']+df['wound_shaman_reduce_value']\n",
    "    #df['pvp_lanch_freque']=df['pvp_lanch_count']/df['avg_online_minutes']\n",
    "    #df['pve_freque']=df['pve_lanch_count']/df['avg_online_minutes']\n",
    "    #df['pvp_freque']=df['pvp_battle_count']/df['avg_online_minutes']\n",
    "    df['wound_left_rate']=(df['wound_cavalry_reduce_value']+df['wound_infantry_reduce_value']+df['wound_shaman_reduce_value'])/df['treatment_acceleration_reduce_value']\n",
    "    return df\n",
    "#test_feat=test_data_prect\n",
    "#train_feat=train_data\n",
    "test_feat=rate_feat(test_data_prect)\n",
    "train_feat=rate_feat(train_data)\n",
    "print('clear_over')\n",
    "#train_data=train_data[train_data['is_clear']==0]\n",
    "\n",
    "\n",
    "#test_feat= test_data_prect[['user_id','pvp_battle_count','pvp_lanch_count','pay_price','avg_online_minutes']]\n",
    "#train_feat= train_data[['user_id','pay_price','pvp_battle_count','pvp_lanch_count','prediction_pay_price','avg_online_minutes']]   \n",
    "#feat=test_data.groupby('user_id').apply(lambda x: rate_feat(x))\n",
    "print('test feat over')\n",
    "#test_feat=test_feat.merge(feat,on='user_id',how='left')  \n",
    "#feat=train_data.groupby('user_id').apply(lambda x: rate_feat(x))\n",
    "print('train feat over')\n",
    "#train_feat=train_feat.merge(feat,on='user_id',how='left')\n",
    "#scaler = MinMaxScaler()\n",
    "def data_scar(data):\n",
    "    '''\n",
    "    #data=data.reshape(-1, 1) \n",
    "    scaler.fit(data)\n",
    "    data=scaler.fit_transform(data)\n",
    "    '''\n",
    "    data=(data-data.min())/(data.max()-data.min())\n",
    "    return data\n",
    "  \n",
    "drop = ['user_id','pay_price']\n",
    "train_feat['label']=train_feat['prediction_pay_price']/train_feat['pay_price']\n",
    "train_idx=train_data[drop]\n",
    "test_idx=test_data_prect[drop]\n",
    "test_idx_rule=test_data_rule[drop]\n",
    "y = train_feat.pop('label')\n",
    "del train_feat['prediction_pay_price']\n",
    "#test_feat['prediction_pay_price']=-111\n",
    "data_feat=pd.concat([train_feat, test_feat])\n",
    "data_feat=data_feat.drop(drop, axis=1)\n",
    "#data_feat=data_feat.replace(np.Inf,0)\n",
    "#data_feat=data_feat.replace(np.NaN,0)\n",
    "#data_feat=data_feat.apply(lambda x:data_scar(x),axis = 0)\n",
    "#data_feat=data_feat.replace(np.Inf,0)\n",
    "y=y.replace(np.NaN,0)\n",
    "train_feat=data_feat[:len(y)]\n",
    "test_feat=data_feat[len(y):]\n",
    "\n",
    "#test_feat=test_feat.drop('prediction_pay_price', axis=1)\n",
    "\n",
    "#train_feat=train_feat.drop(drop, axis=1)\n",
    "#test_feat=test_feat.drop(drop, axis=1)\n",
    "\n",
    "\n",
    "#cols = ['pay_price']\n",
    "'''\n",
    "param = {'learning_rate' : 0.01,\n",
    "        #'n_estimators': 1000,\n",
    "        'max_depth': 6,\n",
    "        'min_child_weight': 5,\n",
    "        'gamma': 0,\n",
    "        'subsample': 0.8,\n",
    "        'colsample_bytree': 0.8,\n",
    "        'eta': 0.01,\n",
    "        #'silent': 1,\n",
    "        'objective':\n",
    "        'reg',\n",
    "        #'scale_pos_weight':1,\n",
    "        'seed':1024}\n",
    "dtrain = xgb.DMatrix(train_feat,label=y)\n",
    "\n",
    "bst = xgb.train(param, dtrain, num_boost_round=100)\n",
    "dtest = xgb.DMatrix(test_feat)\n",
    "y_prob = bst.predict(dtest)\n",
    "'''\n",
    "\n",
    "'''\n",
    "from sklearn.linear_model import LinearRegression\n",
    "print('start')\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(train_feat, y)\n",
    "\n",
    "y_prob = lr.predict(test_feat)\n",
    "\n",
    "'''\n",
    "\n",
    "import lightgbm as lgb\n",
    "lgb_train = lgb.Dataset(train_feat, y)\n",
    "print('开始训练......')\n",
    "\n",
    "params = {\n",
    "            'boosting_type': 'gbdt',\n",
    "            'metric': {'l2',}, \n",
    "#             'is_unbalance':'True',\n",
    "            'learning_rate' : 0.01, \n",
    "             'verbose': 0,\n",
    "#            'num_leaves': 32,\n",
    "#             'max_depth':4, \n",
    "#             'max_bin':10, \n",
    "#             'lambda_l2': 10, \n",
    "            'objective': 'regression', \n",
    "            #'feature_fraction': 0.4,\n",
    "            #'bagging_fraction':0.7, # 0.9是目前最优的\n",
    "#             'bagging_freq':1,  # 3是目前最优的\n",
    "#             'min_data': 500,\n",
    "            'seed': 1024,\n",
    "            'nthread': 12,\n",
    "#             'silent': True,\n",
    "}\n",
    "\n",
    "'''\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'regression',\n",
    "    'metric': {'l2'}\n",
    "}\n",
    "'''\n",
    "gbm = lgb.train(params,\n",
    "                lgb_train,\n",
    "                num_boost_round=170,#220\n",
    "                #valid_sets=lgb_eval\n",
    "                )\n",
    "\n",
    "y_prob = gbm.predict(test_feat)\n",
    "\n",
    "#y_prob=y_prob*test_feat['pay_price']\n",
    "test_idx['label'] = y_prob\n",
    "test_idx['prediction_pay_price']=test_idx['label']*test_idx['pay_price']\n",
    "test_idx_rule['prediction_pay_price']=0\n",
    "\n",
    "res = pd.concat([test_idx, test_idx_rule])\n",
    "\n",
    "res[['user_id','prediction_pay_price']].to_csv(\"new_add_dif_time.csv\", sep=',',index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
